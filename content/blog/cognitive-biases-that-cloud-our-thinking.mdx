---
title: 15 Cognitive Biases That Cloud Our Thinking
description: A practical guide to 15 cognitive biases that distort decision-making in work, data, and everyday life.
published: 2024-11-24T12:00:00.000Z
category: Strategic
author: caryle-blondell
---

<Image
  src="/marketing/blog/cognitive-bias.jpg"
  alt="cognitive-bias"
  width="768"
  height="432"
  className="w-full rounded-lg"
/>

# 15 Cognitive Biases That Cloud Our Thinking

In both technology and operations, decisions made under pressure can create ripple effects—financially, organizationally, and technically. Over the years, I’ve seen how even smart people fall into predictable mental traps. These aren’t just human quirks—they’re cognitive biases that affect how we process information and make choices.

Here are 15 common ones I think about regularly, and how I try to catch myself in the act.

---

## 1. Base-Rate Neglect

We focus on the specific case and ignore the statistical backdrop. A good engineer may dismiss how rarely their scenario actually happens. Whether it’s system failures or customer churn, ignoring base rates distorts risk.

## 2. Clustering Illusion

We see patterns in random data—especially in dashboards or product analytics. This illusion creates false narratives: "users drop off after step 3, so step 3 is broken." Sometimes, randomness is just randomness.

## 3. Confirmation Bias

It’s easier to notice what supports our beliefs than what contradicts them. I’ve caught myself searching logs or running queries that “prove” my theory instead of challenging it. Data shouldn’t be a mirror.

## 4. Overconfidence Effect

We often overestimate our knowledge, especially in areas we feel fluent. I’ve learned that saying “I don’t know” can save far more time than pretending I do.

## 5. Regression to the Mean

If something swings drastically—performance, engagement, outages—it’s likely to return to normal over time. Making big changes based on short-term extremes can be costly.

## 6. Induction

Assuming patterns will continue just because they have. "The system didn’t fail last week, so it won’t fail this week"—until it does. Inductive reasoning is comforting but not always reliable.

## 7. Intention-To-Treat Error

When we evaluate the success of a process but ignore those who dropped out of it, we get skewed results. It’s common in funnel analysis and experimentation. Who *didn’t* make it matters just as much.

## 8. False Causality

Just because two things change together doesn’t mean one caused the other. This bias is rampant in A/B testing, where spurious correlations can lead to false confidence.

## 9. The Problem with Averages

Averages hide variability. A mean engagement time of 5 minutes doesn’t tell you about users who stayed 20 seconds or 2 hours. I’ve learned to dig into distributions—not just summaries.

## 10. Information Bias

Sometimes we want more data even if it won’t change the outcome. I’ve seen this stall decision-making. More isn’t always better—sometimes it’s just noise.

## 11. The Law of Small Numbers

Small samples give us big confidence—incorrectly. Whether it’s testing a feature on 12 users or drawing conclusions from one week's data, we underestimate the role of chance.

## 12. Ambiguity Aversion (Risk vs Uncertainty)

We prefer known risks over unknown ones, even if the unknown has better upside. This plays out in hiring, platform choices, and market expansion. Uncertainty isn't always bad—it’s just harder to measure.

## 13. Planning Fallacy

We consistently underestimate how long tasks will take. Building a feature "in two weeks" has become the punchline of many retrospectives. I’ve learned to pad timelines—and still expect surprises.

## 14. Déformation Professionnelle

We interpret everything through the lens of our expertise. I see this in engineers who want to code their way out of every problem. Sometimes the best fix isn’t technical.

## 15. Exponential Growth Bias

We struggle to intuitively grasp compounding growth. Whether it’s debt, data scale, or user acquisition, we plan linearly when the curve is anything but.

---

## Conclusion

Awareness doesn’t eliminate bias—but it’s the first step. By naming these tendencies, we can pause before reacting and make more grounded decisions. In business, code, or life, that pause is often where clarity begins.

---

## Useful Links

- [The Art of Thinking Clearly by Rolf Dobelli](https://www.goodreads.com/book/show/16248196-the-art-of-thinking-clearly)
- [Base Rate Fallacy (Wikipedia)](https://en.wikipedia.org/wiki/Base_rate_fallacy)
- [Understanding Biases in Data](https://towardsdatascience.com/cognitive-biases-in-data-analysis-3fc945f9a5de)
- [Why Smart People Make Bad Decisions – Farnam Street](https://fs.blog/smart-people-bad-decisions/)


